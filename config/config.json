{   
    "llm_repo_id" : "TheBloke/Llama-2-7b-Chat-GGUF",
    "llm_file_name" : "llama-2-7b-chat.Q4_K_M.gguf",
    "n_gpu_layers" : 100,
    "n_batch" : 1048,
    "n_ctx" : 10000,
    "device" : "cpu",
    "rerank_top_k" : 2,
    "max_token_limit" : 1024,
    "USE_OPENAI_MODEL" : "",

    "data_ingestion" : {
        "embed_model" : "sentence-transformers/all-MiniLM-L6-v2",
        "chunk_size": 500,
        "chunk_overlap": 100,
        "cross_encoder_model" : "cross-encoder/ms-marco-MiniLM-L-6-v2"
    },
    
    "vector_store_dir" : "vectorstore"
}
